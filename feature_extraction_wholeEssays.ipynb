{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open augmented_essays.csv\n",
    "import pandas as pd\n",
    "\n",
    "augmented_df = pd.read_csv('augmented_essays.tsv', encoding='utf_8',sep='\\t')\n",
    "\n",
    "zaebuc_df = pd.read_csv('raw_essays.tsv', encoding='utf_8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 'Raw' and index and to_grade columns\n",
    "grades = augmented_df['to_grade']\n",
    "\n",
    "# create a new dataframe with only the columns we need\n",
    "essays = augmented_df['Raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df['augmented'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw</th>\n",
       "      <th>grade</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>وسائل التواصل الاجتماعي لها اضرار و فوائد كثير...</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR-030-386369</td>\n",
       "      <td>تعد وسائل التواصل الاجتماعي من اكبر المؤثرات ع...</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR-030-81027</td>\n",
       "      <td>قام انتشارالوساءل للتواصل الاجتماعية بشكل كبير...</td>\n",
       "      <td>A2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR-030-81757</td>\n",
       "      <td>وسائل التواصل الاجتماعي لقد تطورت وسائل المعرف...</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR-030-83625</td>\n",
       "      <td>من اشهر وساءل الاتصال بالآخرين هي الاجتماعية،</td>\n",
       "      <td>Unassessable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>AR-130-99351</td>\n",
       "      <td>ظهور الأجهزة الإلكترونية أدى إلى ظهور وسائل ال...</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>AR-130-99438</td>\n",
       "      <td>وسائل التواصل الاجتماعي منذ انتشار وسائل التوا...</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>AR-130-99442</td>\n",
       "      <td>وسائل التواصل الإجتماعي .إنّ التواصل الإجتماعي...</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>AR-130-99590</td>\n",
       "      <td>التسامح أمر مهم جداً يجب على الفرد اخذه بجدية،...</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>التواصل الإجتماعي عبارة عن مجموعة من التكنولوج...</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Document                                                Raw  \\\n",
       "0    AR-030-268469  وسائل التواصل الاجتماعي لها اضرار و فوائد كثير...   \n",
       "1    AR-030-386369  تعد وسائل التواصل الاجتماعي من اكبر المؤثرات ع...   \n",
       "2     AR-030-81027  قام انتشارالوساءل للتواصل الاجتماعية بشكل كبير...   \n",
       "3     AR-030-81757  وسائل التواصل الاجتماعي لقد تطورت وسائل المعرف...   \n",
       "4     AR-030-83625      من اشهر وساءل الاتصال بالآخرين هي الاجتماعية،   \n",
       "..             ...                                                ...   \n",
       "209   AR-130-99351  ظهور الأجهزة الإلكترونية أدى إلى ظهور وسائل ال...   \n",
       "210   AR-130-99438  وسائل التواصل الاجتماعي منذ انتشار وسائل التوا...   \n",
       "211   AR-130-99442  وسائل التواصل الإجتماعي .إنّ التواصل الإجتماعي...   \n",
       "212   AR-130-99590  التسامح أمر مهم جداً يجب على الفرد اخذه بجدية،...   \n",
       "213   AR-130-99787  التواصل الإجتماعي عبارة عن مجموعة من التكنولوج...   \n",
       "\n",
       "            grade  augmented  \n",
       "0              B1          0  \n",
       "1              B2          0  \n",
       "2              A2          0  \n",
       "3              B2          0  \n",
       "4    Unassessable          0  \n",
       "..            ...        ...  \n",
       "209            B2          0  \n",
       "210            B2          0  \n",
       "211            B2          0  \n",
       "212            B1          0  \n",
       "213            B1          0  \n",
       "\n",
       "[214 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zaebuc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zaebuc_df['augmented'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first and last character (')\n",
    "essays = essays.str[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Raw of zaebuc_df to essays and reset index\n",
    "# set the value of augmented to 1 for the new entries\n",
    "essays = essays.append(zaebuc_df['Raw']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A1\n",
       "1      A2\n",
       "2      C1\n",
       "3      C2\n",
       "4      C1\n",
       "       ..\n",
       "619    B2\n",
       "620    B2\n",
       "621    B2\n",
       "622    B1\n",
       "623    B1\n",
       "Length: 624, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = grades.append(zaebuc_df['grade']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "from camel_tools.tokenizers.morphological import MorphologicalTokenizer\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "\n",
    "mle_msa = MLEDisambiguator.pretrained('calima-msa-r13')\n",
    "\n",
    "msa_d3_tokenizer = MorphologicalTokenizer(disambiguator=mle_msa, scheme='atbtok', split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'كان هناك الكثير من التحسينات من الناس الذين جاءوا إلينا من أماكن مختلفة. هم ساعدوا الامارات. أعطونا كل ما نحتاجه. كل ما نريده هو مكان آمن و بلا مشاكل. الامارات أعطتنا مكان آمن أولا. هذا هو السبب الناس يأتون من أماكن بعيدة إلى هنا، بنوا لنا مطاعم جميلة و مدارس و جامعات عالية، أيضا بنوا لنا شوارع و طرق جيدة و قوانين للجميع في الامارات. الأفكار الجميلة جاءت من أماكن مختلفة و الامارات بحثت كثيرا و ذهبت إلى أماكن أخرى لفهم العالم و الأفكار و كيفية بنائها بشكل جيد، هذا يأخذ الكثير من الوقت و العمل، أنا فخورة جدا بأن أكون من الامارات. '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tokenized_essays = []\n",
    "for essay in essays:\n",
    "    simple_tokenized_essays.append(simple_word_tokenize(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagged_sentences = []\n",
    "lex_tagged_sentences = []\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "from camel_tools.tagger.default import DefaultTagger\n",
    "\n",
    "mled = MLEDisambiguator.pretrained()\n",
    "pos_tagger = DefaultTagger(mled, 'pos')\n",
    "lex_tagger = DefaultTagger(mled, 'lex')\n",
    "\n",
    "for essay in simple_tokenized_essays:\n",
    "    pos_tagged_sentences.append(pos_tagger.tag(essay))\n",
    "    lex_tagged_sentences.append(lex_tagger.tag(essay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_words = [[i, pos_word, lex_word] for (i, pos_essay), (j, lex_essay) in zip(enumerate(pos_tagged_sentences), enumerate(lex_tagged_sentences)) for (pos_word, lex_word) in zip(pos_essay, lex_essay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from combined_words\n",
    "words_df = pd.DataFrame(combined_words, columns=['id', 'pos', 'lex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_simple_tokenized_essays = [item for sublist in simple_tokenized_essays for item in sublist]\n",
    "words_df['word'] = flat_simple_tokenized_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "samer_df = pd.read_csv('./samer-readability-lexicon/SAMER-Readability-Lexicon.tsv', encoding='utf_8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_levels(lemmas_pos):\n",
    "    levels = []\n",
    "    for lemma in lemmas_pos:\n",
    "        level = samer_df.loc[samer_df['lemma#pos'] == lemma , 'readability (rounded average)']\n",
    "        if level.empty:\n",
    "            # add the readability score to the dataframe\n",
    "            levels.append(0)\n",
    "            \n",
    "        else:\n",
    "            levels.append(level.values[0])\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df['lemma#pos'] = words_df['lex'] + '#' + words_df['pos']\n",
    "words_df['readability'] = get_levels(words_df['lemma#pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos</th>\n",
       "      <th>lex</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma#pos</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>verb</td>\n",
       "      <td>كان</td>\n",
       "      <td>كان</td>\n",
       "      <td>كان#verb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>adv</td>\n",
       "      <td>هُناكَ</td>\n",
       "      <td>هناك</td>\n",
       "      <td>هُناكَ#adv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>noun</td>\n",
       "      <td>كَثِير</td>\n",
       "      <td>الكثير</td>\n",
       "      <td>كَثِير#noun</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>prep</td>\n",
       "      <td>مِن</td>\n",
       "      <td>من</td>\n",
       "      <td>مِن#prep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>noun</td>\n",
       "      <td>تَحْسِين</td>\n",
       "      <td>التحسينات</td>\n",
       "      <td>تَحْسِين#noun</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>noun</td>\n",
       "      <td>شَكْل</td>\n",
       "      <td>بشكل</td>\n",
       "      <td>شَكْل#noun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>adj</td>\n",
       "      <td>جَيِّد</td>\n",
       "      <td>جيد</td>\n",
       "      <td>جَيِّد#adj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>punc</td>\n",
       "      <td>،</td>\n",
       "      <td>،</td>\n",
       "      <td>،#punc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>pron_dem</td>\n",
       "      <td>هٰذا</td>\n",
       "      <td>هذا</td>\n",
       "      <td>هٰذا#pron_dem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>verb</td>\n",
       "      <td>أَخَذ</td>\n",
       "      <td>يأخذ</td>\n",
       "      <td>أَخَذ#verb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       pos       lex       word      lemma#pos  readability\n",
       "0    0      verb       كان        كان       كان#verb            1\n",
       "1    0       adv    هُناكَ       هناك     هُناكَ#adv            1\n",
       "2    0      noun    كَثِير     الكثير    كَثِير#noun            0\n",
       "3    0      prep       مِن         من       مِن#prep            1\n",
       "4    0      noun  تَحْسِين  التحسينات  تَحْسِين#noun            3\n",
       "..  ..       ...       ...        ...            ...          ...\n",
       "95   0      noun     شَكْل       بشكل     شَكْل#noun            1\n",
       "96   0       adj    جَيِّد        جيد     جَيِّد#adj            1\n",
       "97   0      punc         ،          ،         ،#punc            0\n",
       "98   0  pron_dem      هٰذا        هذا  هٰذا#pron_dem            1\n",
       "99   0      verb     أَخَذ       يأخذ     أَخَذ#verb            1\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df\n",
    "documents_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique id get the counts of readability scores\n",
    "for i in words_df['id'].unique():\n",
    "    # divide the counts by the total number of words in the essay\n",
    "    counts = words_df.loc[words_df['id'] == i, 'readability'].value_counts()\n",
    "    # add th counts to documents_df\n",
    "    documents_df = documents_df.append(counts, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to documents_df for ratios of noun, verb, adj, adv, prep, conj, pron\n",
    "documents_df['noun_ratio'] = 0\n",
    "documents_df['verb_ratio'] = 0\n",
    "documents_df['adj_ratio'] = 0\n",
    "documents_df['adv_ratio'] = 0\n",
    "documents_df['prep_ratio'] = 0\n",
    "documents_df['conj_ratio'] = 0\n",
    "documents_df['pron_ratio'] = 0\n",
    "documents_df['word_count'] = 0\n",
    "documents_df['grade'] = grades\n",
    "\n",
    "# for each unique id get the ratio of noun, verb, adj, adv, prep, conj, pron\n",
    "for i in words_df['id'].unique():\n",
    "    counts = words_df.loc[words_df['id'] == i, 'pos'].value_counts()\n",
    "\n",
    "    # Add the ratios to the corresponding columns in documents_df\n",
    "    total_count = counts.sum()\n",
    "    documents_df.loc[i, 'word_count'] = total_count\n",
    "    if 'noun' in counts:\n",
    "        documents_df.loc[i, 'noun_ratio'] = counts['noun'] / total_count\n",
    "    if 'verb' in counts:\n",
    "        documents_df.loc[i, 'verb_ratio'] = counts['verb'] / total_count\n",
    "    if 'adj' in counts:\n",
    "        documents_df.loc[i, 'adj_ratio'] = counts['adj'] / total_count\n",
    "    if 'adv' in counts:\n",
    "        documents_df.loc[i, 'adv_ratio'] = counts['adv'] / total_count\n",
    "    if 'prep' in counts:\n",
    "        documents_df.loc[i, 'prep_ratio'] = counts['prep'] / total_count\n",
    "    if 'conj' in counts:\n",
    "        documents_df.loc[i, 'conj_ratio'] = counts['conj'] / total_count\n",
    "    if 'pron' in counts:\n",
    "        documents_df.loc[i, 'pron_ratio'] = counts['pron'] / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 1\t0\t3\t2\t4\t5 to readability_1 readability_0 readability_3 readability_2 readability_4 readability_5\n",
    "documents_df.columns = ['readability_1', 'readability_0', 'readability_3', 'readability_2', 'readability_4', 'readability_5', 'noun_ratio', 'verb_ratio', 'adj_ratio', 'adv_ratio', 'prep_ratio', 'conj_ratio', 'pron_ratio', 'word_count', 'grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values of readability_1 to readability_1/word_count\n",
    "documents_df['readability_1'] = documents_df['readability_1'] / documents_df['word_count']\n",
    "documents_df['readability_0'] = documents_df['readability_0'] / documents_df['word_count']\n",
    "documents_df['readability_3'] = documents_df['readability_3'] / documents_df['word_count']\n",
    "documents_df['readability_2'] = documents_df['readability_2'] / documents_df['word_count']\n",
    "documents_df['readability_4'] = documents_df['readability_4'] / documents_df['word_count']\n",
    "documents_df['readability_5'] = documents_df['readability_5'] / documents_df['word_count']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_different_letters(word1, word2):\n",
    "    count = 0\n",
    "    length = min(len(word1), len(word2))\n",
    "    maxi = max(len(word1), len(word2))\n",
    "    count = maxi - length\n",
    "\n",
    "    # Count the number of different letters\n",
    "    count = count + sum(1 for c1, c2 in zip(word1[:length], word2[:length]) if c1 != c2)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos</th>\n",
       "      <th>lex</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma#pos</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>verb</td>\n",
       "      <td>كان</td>\n",
       "      <td>كان</td>\n",
       "      <td>كان#verb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>adv</td>\n",
       "      <td>هُناكَ</td>\n",
       "      <td>هناك</td>\n",
       "      <td>هُناكَ#adv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>noun</td>\n",
       "      <td>كَثِير</td>\n",
       "      <td>الكثير</td>\n",
       "      <td>كَثِير#noun</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>prep</td>\n",
       "      <td>مِن</td>\n",
       "      <td>من</td>\n",
       "      <td>مِن#prep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>noun</td>\n",
       "      <td>تَحْسِين</td>\n",
       "      <td>التحسينات</td>\n",
       "      <td>تَحْسِين#noun</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93469</th>\n",
       "      <td>623</td>\n",
       "      <td>conj</td>\n",
       "      <td>وَ</td>\n",
       "      <td>و</td>\n",
       "      <td>وَ#conj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93470</th>\n",
       "      <td>623</td>\n",
       "      <td>noun</td>\n",
       "      <td>كَيْفِيَّة</td>\n",
       "      <td>كيفية</td>\n",
       "      <td>كَيْفِيَّة#noun</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93471</th>\n",
       "      <td>623</td>\n",
       "      <td>noun</td>\n",
       "      <td>ٱِسْتِعْمال</td>\n",
       "      <td>إستعمالهم</td>\n",
       "      <td>ٱِسْتِعْمال#noun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93472</th>\n",
       "      <td>623</td>\n",
       "      <td>prep</td>\n",
       "      <td>لِ</td>\n",
       "      <td>لها</td>\n",
       "      <td>لِ#prep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93473</th>\n",
       "      <td>623</td>\n",
       "      <td>punc</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.#punc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93474 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   pos          lex       word         lemma#pos  readability\n",
       "0        0  verb          كان        كان          كان#verb            1\n",
       "1        0   adv       هُناكَ       هناك        هُناكَ#adv            1\n",
       "2        0  noun       كَثِير     الكثير       كَثِير#noun            0\n",
       "3        0  prep          مِن         من          مِن#prep            1\n",
       "4        0  noun     تَحْسِين  التحسينات     تَحْسِين#noun            3\n",
       "...    ...   ...          ...        ...               ...          ...\n",
       "93469  623  conj           وَ          و           وَ#conj            1\n",
       "93470  623  noun   كَيْفِيَّة      كيفية   كَيْفِيَّة#noun            4\n",
       "93471  623  noun  ٱِسْتِعْمال  إستعمالهم  ٱِسْتِعْمال#noun            1\n",
       "93472  623  prep           لِ        لها           لِ#prep            1\n",
       "93473  623  punc            .          .            .#punc            0\n",
       "\n",
       "[93474 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "\n",
    "mle = MLEDisambiguator.pretrained()\n",
    "\n",
    "\n",
    "errors = []\n",
    "for word in words_df['word']:\n",
    "        # if word is string\n",
    "    if isinstance(word, str):\n",
    "        disambig = mle.disambiguate([str(word)])\n",
    "        dediac_word = dediac_ar(word)\n",
    "        dediac_disambig = dediac_ar(disambig[0].analyses[0].analysis['diac'])\n",
    "        # print(word)\n",
    "        # print(dediac_disambig)\n",
    "        if dediac_word == 'و':\n",
    "            errors.append(2)\n",
    "        elif dediac_word != dediac_disambig:\n",
    "            # check how many letters are different\n",
    "            errors.append(count_different_letters(dediac_word, dediac_disambig))\n",
    "        else:\n",
    "            errors.append(0)\n",
    "    else:\n",
    "        errors.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df['error'] = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv('words_df.csv', encoding='utf_8',sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df = pd.DataFrame()\n",
    "\n",
    "# calculate the error rate\n",
    "documents_df['error_rate'] = words_df.groupby('id')['error'].sum() / documents_df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat ['augemented'] and zaebuc_df['augemented'] and add it to documents_df\n",
    "documents_df['augmented'] = augmented_df['augmented'].append(zaebuc_df['augmented']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Document'] = augmented_df['Document'].append(zaebuc_df['Document']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df.to_csv('documents_features.csv', encoding='utf_8',sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
