{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt1NGLZqJYWI"
      },
      "outputs": [],
      "source": [
        "pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import requests\n",
        "from functools import partial\n",
        "import csv\n",
        "from dataclasses import dataclass\n",
        "import pandas as pd\n",
        "import conllu\n",
        "from conllu import parse"
      ],
      "metadata": {
        "id": "K0S8sBLOJbOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "depth_df = pd.DataFrame(columns=['Sentence', 'Tree Depth'])\n",
        "csv_filename = 'sentences_and_depths.csv'\n",
        "\n",
        "def calculate_tree_depth(sentence):\n",
        "    def get_depth(token_id, token_dict, depth=0):\n",
        "        children = [t for t in sentence if t['head'] == token_id]\n",
        "        if not children:\n",
        "            return depth\n",
        "        return max(get_depth(child['id'], token_dict, depth + 1) for child in children)\n",
        "\n",
        "    # Create a dictionary for quick access to tokens by their id\n",
        "    token_dict = {token['id']: token for token in sentence}\n",
        "\n",
        "    # The root token has a 'head' value of 0, start from there\n",
        "    return get_depth(0, token_dict)\n",
        "\n",
        "Result_df = pd.DataFrame()\n",
        "\n",
        "payload = {\n",
        "    \"data\": \"I Love NLP very much\",\n",
        "    \"tokenizer\": \"ranges\",\n",
        "    \"model\": \"english-atis-ud-2.12-230717\",\n",
        "    \"tagger\": True,\n",
        "    \"parser\": True\n",
        "}\n",
        "\n",
        "filename = \"/content/drive/MyDrive/NLP - Project/output.csv\" #CSV input should only have one column called \"Raw\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Row:\n",
        "    text: str\n",
        "\n",
        "\n",
        "def get_csv_reader():\n",
        "    return partial(csv.reader)\n",
        "\n",
        "\n",
        "with open(filename, encoding=\"utf-8\") as file:\n",
        "    reader = get_csv_reader()\n",
        "    for row in reader(file):\n",
        "        try:\n",
        "            r = Row(*row)\n",
        "            payload = {\n",
        "                \"data\": f\"{r.text}\",\n",
        "                \"tokenizer\": \"ranges\",\n",
        "                \"model\": \"arabic-padt-ud-2.12-230717\",\n",
        "                \"tagger\": True,\n",
        "                \"parser\": True,\n",
        "            }\n",
        "            response = requests.post(\"https://lindat.mff.cuni.cz/services/udpipe/api/process\", data=payload)\n",
        "            result = response.json().get(\"result\", None)\n",
        "            # print(result)\n",
        "            Con = parse(result)\n",
        "            # print(f\"\\n\\nParse:\", Con)\n",
        "            for sentence in Con:\n",
        "              depth = calculate_tree_depth(sentence)\n",
        "              sentence_str = ' '.join([token['form'] for token in sentence])\n",
        "              depth_df = depth_df.append({'Sentence': sentence_str, 'Tree Depth': depth}, ignore_index=True)\n",
        "              depth_df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
        "              # print(\"Parse:\", sentence)\n",
        "              # print(\"Tree depth:\", depth)\n",
        "              # print(\"#\" * 50, \"\\n\")  # Separator for readability\n",
        "\n",
        "            # Result_df = pd.DataFrame(list(Con))\n",
        "            # print(\"Dataframe:\", Result_df )\n",
        "            # print(\"\\n\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Operation got an Error: {e}\")\n",
        "            raise Exception\n",
        "\n",
        "\n",
        "#Result_df.to_#csv('API-results.csv')"
      ],
      "metadata": {
        "id": "Hs4hae4WJcJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XKTl-OLJb9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fVqyWapWJbzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}