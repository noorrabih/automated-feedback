{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e74c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e90945",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZAEBUC_AR_COR = pd.read_csv('ZAEBUC-v1.0/AR-all.extracted.corrected.analyzed.corrected-FINAL.tsv', encoding='utf_8',sep='\\t')\n",
    "words_df = ZAEBUC_AR_COR[ZAEBUC_AR_COR['Word'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b10ce334",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZAEBUC_AR_ALL = pd.read_csv('ZAEBUC-v1.0/AR-all.alignment-FINAL.tsv', encoding='utf_8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52a7bb0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Corrected</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>وسائل</td>\n",
       "      <td>وسائل</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>التواصل</td>\n",
       "      <td>التواصل</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>الاجتماعي</td>\n",
       "      <td>الاجتماعي</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>لها</td>\n",
       "      <td>لها</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>اضرار</td>\n",
       "      <td>أضرار</td>\n",
       "      <td>EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33761</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>المجتمع</td>\n",
       "      <td>المجتمع</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33762</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>و</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33763</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>كيفية</td>\n",
       "      <td>وكيفية</td>\n",
       "      <td>EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33764</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>إستعمالهم</td>\n",
       "      <td>استعمالهم</td>\n",
       "      <td>EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33765</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>لها.</td>\n",
       "      <td>لها.</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33766 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Document        Raw  Corrected  Operation\n",
       "0      AR-030-268469      وسائل      وسائل  NO_CHANGE\n",
       "1      AR-030-268469    التواصل    التواصل  NO_CHANGE\n",
       "2      AR-030-268469  الاجتماعي  الاجتماعي  NO_CHANGE\n",
       "3      AR-030-268469        لها        لها  NO_CHANGE\n",
       "4      AR-030-268469      اضرار      أضرار       EDIT\n",
       "...              ...        ...        ...        ...\n",
       "33761   AR-130-99787    المجتمع    المجتمع  NO_CHANGE\n",
       "33762   AR-130-99787          و        NaN     DELETE\n",
       "33763   AR-130-99787      كيفية     وكيفية       EDIT\n",
       "33764   AR-130-99787  إستعمالهم  استعمالهم       EDIT\n",
       "33765   AR-130-99787       لها.       لها.  NO_CHANGE\n",
       "\n",
       "[33766 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZAEBUC_AR_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c96439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO_CHANGE', 'EDIT', 'DELETE', 'INSERT'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZAEBUC_AR_ALL['Operation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f5dc961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_df = ZAEBUC_AR_ALL[['Document','Operation']].groupby('Document').aggregate({'Operation': (lambda x: 1- np.sum(x=='NO_CHANGE')/len(x) )}).rename(columns = {'Operation':'error_rate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a26a6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR-030-268469</th>\n",
       "      <td>0.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-386369</th>\n",
       "      <td>0.237179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81027</th>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81757</th>\n",
       "      <td>0.493927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-83625</th>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99351</th>\n",
       "      <td>0.245283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99438</th>\n",
       "      <td>0.059322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99442</th>\n",
       "      <td>0.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99590</th>\n",
       "      <td>0.126214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99787</th>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               error_rate\n",
       "Document                 \n",
       "AR-030-268469    0.455621\n",
       "AR-030-386369    0.237179\n",
       "AR-030-81027     0.585366\n",
       "AR-030-81757     0.493927\n",
       "AR-030-83625     0.428571\n",
       "...                   ...\n",
       "AR-130-99351     0.245283\n",
       "AR-130-99438     0.059322\n",
       "AR-130-99442     0.311475\n",
       "AR-130-99590     0.126214\n",
       "AR-130-99787     0.291667\n",
       "\n",
       "[214 rows x 1 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672efc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays_df = words_df[['Document','Auto_Tokenization']].groupby(by = 'Document').agg({'Auto_Tokenization': ' '.join})\n",
    "tokenized_essays_df['Auto_Tokenization'] = tokenized_essays_df['Auto_Tokenization'].apply(lambda x : x.replace('+', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b8f410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto_Tokenization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR-030-268469</th>\n",
       "      <td>وسائل التواصل الاجتماعي ل ها أضرار و فوائد كثي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-386369</th>\n",
       "      <td>تعد وسائل التواصل الاجتماعي من أكبر المؤثرات ع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81027</th>\n",
       "      <td>قام انتشار وسائل التواصل الاجتماعي ب شكل كبير ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81757</th>\n",
       "      <td>وسائل التواصل الاجتماعي لقد تطورت وسائل المعرف...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-83625</th>\n",
       "      <td>من أشهر وسائل الاتصال ب الآخرين هي الاجتماعية .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99351</th>\n",
       "      <td>ظهور الأجهزة الإلكترونية أدى إلى ظهور وسائل ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99438</th>\n",
       "      <td>وسائل التواصل الاجتماعي منذ انتشار وسائل التوا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99442</th>\n",
       "      <td>وسائل التواصل الاجتماعي إن التواصل الاجتماعي ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99590</th>\n",
       "      <td>التسامح أمر مهم جدا يجب على الفرد أخذ ه ب جدية...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99787</th>\n",
       "      <td>التواصل الاجتماعي عبارة عن مجموعة من التكنولوج...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Auto_Tokenization\n",
       "Document                                                        \n",
       "AR-030-268469  وسائل التواصل الاجتماعي ل ها أضرار و فوائد كثي...\n",
       "AR-030-386369  تعد وسائل التواصل الاجتماعي من أكبر المؤثرات ع...\n",
       "AR-030-81027   قام انتشار وسائل التواصل الاجتماعي ب شكل كبير ...\n",
       "AR-030-81757   وسائل التواصل الاجتماعي لقد تطورت وسائل المعرف...\n",
       "AR-030-83625     من أشهر وسائل الاتصال ب الآخرين هي الاجتماعية .\n",
       "...                                                          ...\n",
       "AR-130-99351   ظهور الأجهزة الإلكترونية أدى إلى ظهور وسائل ال...\n",
       "AR-130-99438   وسائل التواصل الاجتماعي منذ انتشار وسائل التوا...\n",
       "AR-130-99442   وسائل التواصل الاجتماعي إن التواصل الاجتماعي ل...\n",
       "AR-130-99590   التسامح أمر مهم جدا يجب على الفرد أخذ ه ب جدية...\n",
       "AR-130-99787   التواصل الاجتماعي عبارة عن مجموعة من التكنولوج...\n",
       "\n",
       "[214 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_essays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93df1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(doc):\n",
    "#     doc = doc.split(' ')\n",
    "#     doc = tokenizer.tokenize(doc)\n",
    "#     tokens = []\n",
    "#     for word in doc:\n",
    "#         word = word.replace('+_', ',').replace('_+',',').split(',')\n",
    "#         for tok in word:\n",
    "#             tokens.append(tok)\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66158384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Applying TFIDF\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1, 1) )\n",
    "doc2vec = vectorizer.fit_transform(tokenized_essays_df['Auto_Tokenization'])\n",
    "doc2vec = (doc2vec.toarray())\n",
    "print(\"\\n\\nScores : \\n\", doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bcbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays_df['Auto_POS'] = words_df[['Document', 'Auto_POS']].groupby(by = 'Document', as_index = True).agg({'Auto_POS': ' '.join})\n",
    "tokenized_essays_df['Auto_POS'] = tokenized_essays_df['Auto_POS'].apply(lambda x: x.replace('+', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d643d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0.19436809 0.         0.07920732 ... 0.         0.         0.02296755]\n",
      " [0.29714894 0.0171133  0.08351155 ... 0.         0.         0.        ]\n",
      " [0.32720461 0.         0.08333737 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.1976791  0.04306373 0.07004921 ... 0.         0.0155246  0.        ]\n",
      " [0.2220965  0.         0.0808098  ... 0.         0.02865505 0.        ]\n",
      " [0.26979631 0.02503347 0.07635085 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Applying TFIDF\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1, 2))\n",
    "pos2vec = vectorizer.fit_transform(tokenized_essays_df['Auto_POS'])\n",
    "pos2vec = (pos2vec.toarray())\n",
    "print(\"\\n\\nScores : \\n\", pos2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "112257b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "docs = ZAEBUC_AR_COR['Document'].apply(lambda x: x if x.startswith('<') else np.nan).dropna()\n",
    "\n",
    "grades = []\n",
    "word_count = []\n",
    "\n",
    "for xml in docs:\n",
    "    if xml != \"</doc>\":\n",
    "        doc = xmltodict.parse(xml)\n",
    "        grades.append(doc[\"doc\"][\"@CEFR\"])\n",
    "        word_count.append(doc[\"doc\"][\"@word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "28729308",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((doc2vec,pos2vec, np.array(word_count).reshape(-1,1), np.array(error_rate_df['error_rate']).reshape(-1,1) ), axis = 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f48135f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  1  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 2  0 20  1  0]\n",
      " [ 0  0  3 10  0]\n",
      " [ 0  0  0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A0       0.50      0.67      0.57         3\n",
      "          A2       0.00      0.00      0.00         2\n",
      "          B1       0.77      0.87      0.82        23\n",
      "          B2       0.77      0.77      0.77        13\n",
      "          C1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.41      0.46      0.43        43\n",
      "weighted avg       0.68      0.74      0.71        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier for X and grades\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, grades, test_size = 0.20)\n",
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14279ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = list(map(lambda x:'A0' if (x == 'Unassessable') else x, grades))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be39186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grades_to_num(grades):\n",
    "    num_grades = []\n",
    "    for x in grades:\n",
    "        match x:\n",
    "            case 'A0':\n",
    "                num_grades.append(0)\n",
    "            case 'A1':\n",
    "                num_grades.append(1)\n",
    "            case 'A2':\n",
    "                num_grades.append(2)\n",
    "            case 'B1':\n",
    "                num_grades.append(3)\n",
    "            case 'B2':\n",
    "                num_grades.append(4)\n",
    "            case 'C1':\n",
    "                num_grades.append(5)\n",
    "            case 'C2':\n",
    "                num_grades.append(6)\n",
    "    return num_grades\n",
    "num_grades = grades_to_num(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d75184cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, num_grades, test_size = 0.20, stratify = num_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90bcc633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## given a dataset X and grades y, return a dataset of pair-wise differences and labels (+,-) \n",
    "def to_pairs(X, y):\n",
    "    paired_X = list()\n",
    "    paired_y = list()\n",
    "    for i in range(len(X)):\n",
    "        for k in range(i+1, len(X), 1):\n",
    "                paired_X.append(np.subtract(X[i], X[k]))\n",
    "                paired_y.append(y[i] > y[k])\n",
    "    return paired_X, paired_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "69efe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_diff, y_train_diff = to_pairs(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e4ae1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_diff, y_test_diff = to_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b35437e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[622  60]\n",
      " [111 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.91      0.88       682\n",
      "        True       0.65      0.50      0.56       221\n",
      "\n",
      "    accuracy                           0.81       903\n",
      "   macro avg       0.75      0.70      0.72       903\n",
      "weighted avg       0.80      0.81      0.80       903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'C': [0.1,1, 10, 100], 'kernel' : ['linear']}\n",
    "\n",
    "# grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "# grid.fit(X_train_diff,y_train_diff)\n",
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train_diff, y_train_diff)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test_diff)\n",
    "\n",
    "print(confusion_matrix(y_test_diff,y_pred))\n",
    "print(classification_report(y_test_diff,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3dfe7ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70136116 4.04085761 2.92069347 4.04101689 4.047345   4.04357734\n",
      " 2.91613167 5.16787871 2.92502935 4.04269002 4.04229931 2.92523018\n",
      " 2.92176802 4.04505568 2.92519778 4.0493465  2.92262226 2.92080762\n",
      " 2.92018631 4.04244097 5.16611018 2.92251306 2.92056449 4.04514666\n",
      " 4.05080357 2.92312745 2.92596179 2.92659206 2.92062573 2.92068064\n",
      " 2.92545877 1.8053114  2.92194922 4.04410498 1.80724442 2.92192447\n",
      " 2.91991227 4.04826155 4.04857454 2.92258587 2.92086489 2.92348876\n",
      " 4.04406268 4.04659006 2.92395006 4.04452296 0.68972742 2.92366657\n",
      " 2.91505458 5.16360668 2.91937368 2.917363   2.91674852 4.04750993\n",
      " 2.92596917 4.04345289 5.1655644  4.04432169 4.04997626 2.92143784\n",
      " 2.91621682 5.16627521 2.91711468 4.05041687 2.92418323 2.92325586\n",
      " 2.92690098 4.04737717 2.92662435 1.80157652 2.9229217  4.04799789\n",
      " 2.92329069 2.92362684 2.92450547 2.92232631 2.92304793 2.92563445\n",
      " 5.17288191 2.91569915 2.92182398 2.91742176 4.04590192 2.9187649\n",
      " 5.1667127  2.9197145  4.04134472 4.0469807  2.92461923 4.04694577\n",
      " 4.04917313 1.80030768 4.04804762 2.91880693 2.92707684 4.04898006\n",
      " 4.04448821 4.04482902 2.92558584 4.04731273 4.04738087 4.05032136\n",
      " 4.04366363 2.9212549  2.9218272  4.04261674 2.92639926 2.91894025\n",
      " 2.92674909 2.91895388 4.04492921 4.04938861 2.91753178 4.04869959\n",
      " 2.92057409 4.04687851 4.04790067 4.04914238 4.05061052 2.92749636\n",
      " 2.92035284 4.04572453 4.04895304 2.92377222 4.04630542 2.92287373\n",
      " 2.91880671 2.92268367 2.92060056 2.91853248 2.92252181 4.04161289\n",
      " 5.15932168 2.91852543 4.0443779  2.92478148 4.04316459 2.92516241\n",
      " 2.91978631 2.92628138 4.04252482 0.68811005 4.04352649 2.92434894\n",
      " 4.04300038 0.68978708 2.92197678 2.92448499 4.04356317 1.79859052\n",
      " 5.15762178 2.92024985 2.9175978  2.92121847 4.04418337 2.91620773\n",
      " 4.0412342  0.68978165 4.04382251 4.04137189 4.04307427 2.91846181\n",
      " 2.91847765 4.04702067 4.04619264 2.92275421 2.92491062 2.91937482\n",
      " 2.92744816 4.03928481 4.04144455]\n",
      "[0, 4, 3, 4, 4, 4, 3, 5, 3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 3, 4, 5, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 4, 2, 3, 3, 4, 4, 3, 3, 3, 4, 4, 3, 4, 0, 3, 3, 5, 3, 3, 3, 4, 3, 4, 5, 4, 4, 3, 3, 5, 3, 4, 3, 3, 3, 4, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 5, 3, 4, 4, 3, 4, 4, 2, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 4, 5, 3, 4, 3, 4, 3, 3, 3, 4, 0, 4, 3, 4, 0, 3, 3, 4, 2, 5, 3, 3, 3, 4, 3, 4, 0, 4, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "svc_fitted_X_train = svclassifier.coef_ @ np.transpose(X_train)\n",
    "svc_fitted_X_train = svc_fitted_X_train.reshape(-1,1) \n",
    "svc_fitted_X_test = svclassifier.coef_ @ np.transpose(X_test)\n",
    "svc_fitted_X_test = svc_fitted_X_test.reshape(-1,1) \n",
    "\n",
    "lm= LinearRegression(fit_intercept=True).fit(svc_fitted_X_train, y_train)\n",
    "print(lm.predict(svc_fitted_X_train))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "944e17bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.11403801 3.        ]\n",
      " [3.66988224 3.        ]\n",
      " [3.19526027 3.        ]\n",
      " [3.68525779 3.        ]\n",
      " [3.97268812 4.        ]\n",
      " [2.99957639 3.        ]\n",
      " [3.58183605 3.        ]\n",
      " [3.54325607 4.        ]\n",
      " [1.6514533  2.        ]\n",
      " [3.84400754 4.        ]\n",
      " [3.46003881 3.        ]\n",
      " [3.20890867 4.        ]\n",
      " [3.06546325 3.        ]\n",
      " [3.58727746 4.        ]\n",
      " [3.04185278 3.        ]\n",
      " [3.00173177 3.        ]\n",
      " [3.90402768 4.        ]\n",
      " [3.02947964 0.        ]\n",
      " [3.36087306 3.        ]\n",
      " [2.76261129 2.        ]\n",
      " [4.06777204 4.        ]\n",
      " [3.57963062 4.        ]\n",
      " [3.51854575 3.        ]\n",
      " [4.31810252 4.        ]\n",
      " [2.68096896 3.        ]\n",
      " [3.75726252 4.        ]\n",
      " [3.05665264 4.        ]\n",
      " [2.78215381 3.        ]\n",
      " [3.2666612  3.        ]\n",
      " [3.72336252 4.        ]\n",
      " [3.45763205 4.        ]\n",
      " [3.27444785 4.        ]\n",
      " [3.08822743 3.        ]\n",
      " [3.15551354 3.        ]\n",
      " [4.09474819 5.        ]\n",
      " [2.48587472 3.        ]\n",
      " [3.55044447 3.        ]\n",
      " [4.47608643 5.        ]\n",
      " [3.70220535 4.        ]\n",
      " [2.81434992 3.        ]\n",
      " [3.81520117 4.        ]\n",
      " [3.4517561  3.        ]\n",
      " [3.28445553 3.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((np.array(lm.predict(svc_fitted_X_test)).reshape(-1,1), np.array(y_test).reshape(-1,1)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "68d8ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3.]\n",
      " [4. 3.]\n",
      " [3. 3.]\n",
      " [4. 3.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [4. 3.]\n",
      " [4. 4.]\n",
      " [2. 2.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [3. 0.]\n",
      " [3. 3.]\n",
      " [3. 2.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 3.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [3. 4.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 5.]\n",
      " [2. 3.]\n",
      " [4. 3.]\n",
      " [4. 5.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "predicted_grades = np.floor(np.array(lm.predict(svc_fitted_X_test)).reshape(-1,1) + 0.5)\n",
    "print(np.concatenate((predicted_grades, np.array(y_test).reshape(-1,1)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "09ce8cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.53693014],\n",
       "       [0.53693014, 1.        ]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.floor(np.array(lm.predict(svc_fitted_X_test)) + 0.5), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d33a961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  0  0]\n",
      " [ 0  1  1  0  0]\n",
      " [ 0  1 16  5  0]\n",
      " [ 0  0  4 12  0]\n",
      " [ 0  0  0  2  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, np.floor(np.array(lm.predict(svc_fitted_X_test)) + 0.5))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "307ce397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.50      0.50      0.50         2\n",
      "           3       0.73      0.73      0.73        22\n",
      "           4       0.63      0.75      0.69        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67        43\n",
      "   macro avg       0.37      0.40      0.38        43\n",
      "weighted avg       0.63      0.67      0.65        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,np.floor(np.array(lm.predict(svc_fitted_X_test)) + 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84cfb5b",
   "metadata": {},
   "source": [
    "## Linear Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "310589cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.6976744186046512\n",
      "[[ 0  0  1  0  0]\n",
      " [ 0  1  1  0  0]\n",
      " [ 0  0 17  5  0]\n",
      " [ 0  0  4 12  0]\n",
      " [ 0  0  0  2  0]]\n"
     ]
    }
   ],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(svc_fitted_X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(svc_fitted_X_test)\n",
    "\n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(svc_fitted_X_test, y_test) \n",
    "print('accuracy= {}'.format(accuracy))\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e7129cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       0.74      0.77      0.76        22\n",
      "           4       0.63      0.75      0.69        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.70        43\n",
      "   macro avg       0.47      0.40      0.42        43\n",
      "weighted avg       0.66      0.70      0.67        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanad/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
