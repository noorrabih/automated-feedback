{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import Data \n",
    "# open augmented_essays.csv\n",
    "import pandas as pd\n",
    "\n",
    "augmented_df = pd.read_csv('augmented_essays.tsv', encoding='utf_8',sep='\\t')\n",
    "\n",
    "zaebuc_df = pd.read_csv('raw_essays.tsv', encoding='utf_8',sep='\\t')\n",
    "zaebuc_df = zaebuc_df[zaebuc_df['grade'] != 'Unassessable']\n",
    "\n",
    "# create a new dataframe with only the columns we need\n",
    "essays = augmented_df['Raw']\n",
    "# remove first and last character (')\n",
    "essays = essays.str[1:-1]\n",
    "# add Raw of zaebuc_df to essays and reset index\n",
    "essays = essays.append(zaebuc_df['Raw']).reset_index(drop=True)\n",
    "# create a new dataframe with essays\n",
    "essays_df = pd.DataFrame(essays, columns=['Raw'])\n",
    "# open documents_df.csv\n",
    "documents_df = pd.read_csv('documents_features.csv', encoding='utf_8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = documents_df['grade']\n",
    "grades = grades[grades != 'Unassessable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1    116\n",
       "A2    111\n",
       "B1    110\n",
       "A1    105\n",
       "C2     96\n",
       "B2     80\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df = documents_df[documents_df['grade'] != 'Unassessable']\n",
    "# fix the index\n",
    "documents_df = documents_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# tokenize raw data and add it to the dataframe\n",
    "essays_df['Tokenized'] = essays_df['Raw'].apply(lambda x: simple_word_tokenize(x))\n",
    "# concatenate essays_df and documents_df\n",
    "df = pd.concat([essays_df, documents_df], axis=1)\n",
    "# remove 'Unnamed: 0' column\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get doc2vec vectors for raw data\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "#tag the documents\n",
    "tagged_data = [TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(df['Tokenized'])]\n",
    "\n",
    "#train the model\n",
    "max_epochs = 100\n",
    "vec_size = 100\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "    \n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    \n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor/anaconda3/envs/CAMeLBERT_morphosyntactic_tagger/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "# get vectors for the raw data\n",
    "vectors = []\n",
    "for i in range(len(df)):\n",
    "    vectors.append(model.docvecs[i])\n",
    "\n",
    "#add vectors to dataframe with Document as index\n",
    "df['Doc2Vec Embeddings'] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all A1 and A2 to A\n",
    "df['grade'] = df['grade'].replace(['A1', 'A2'], 'A')\n",
    "\n",
    "# change all C1 and C2 to C\n",
    "df['grade'] = df['grade'].replace(['C1', 'C2'], 'C')\n",
    "\n",
    "# change all B1 and B2 to B\n",
    "# df['grade'] = df['grade'].replace(['B1', 'B2'], 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability_1</th>\n",
       "      <th>readability_3</th>\n",
       "      <th>readability_2</th>\n",
       "      <th>readability_4</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adj_ratio</th>\n",
       "      <th>adv_ratio</th>\n",
       "      <th>prep_ratio</th>\n",
       "      <th>conj_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587719</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164104</td>\n",
       "      <td>4.349712</td>\n",
       "      <td>3.254559</td>\n",
       "      <td>-0.531110</td>\n",
       "      <td>3.654962</td>\n",
       "      <td>0.230786</td>\n",
       "      <td>1.026072</td>\n",
       "      <td>-1.068444</td>\n",
       "      <td>-2.384245</td>\n",
       "      <td>4.848377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.048544</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>...</td>\n",
       "      <td>1.280848</td>\n",
       "      <td>1.549968</td>\n",
       "      <td>1.749696</td>\n",
       "      <td>0.601716</td>\n",
       "      <td>5.797670</td>\n",
       "      <td>5.229796</td>\n",
       "      <td>3.746816</td>\n",
       "      <td>0.156839</td>\n",
       "      <td>-5.438986</td>\n",
       "      <td>4.569999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.220238</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.136905</td>\n",
       "      <td>0.136905</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.027658</td>\n",
       "      <td>-0.169038</td>\n",
       "      <td>2.459741</td>\n",
       "      <td>0.418934</td>\n",
       "      <td>7.791171</td>\n",
       "      <td>5.558947</td>\n",
       "      <td>6.597505</td>\n",
       "      <td>-0.807560</td>\n",
       "      <td>-1.421728</td>\n",
       "      <td>4.696105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393548</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.092911</td>\n",
       "      <td>-2.561067</td>\n",
       "      <td>2.664188</td>\n",
       "      <td>-0.502632</td>\n",
       "      <td>2.867926</td>\n",
       "      <td>5.306192</td>\n",
       "      <td>2.735043</td>\n",
       "      <td>-2.377146</td>\n",
       "      <td>-2.957879</td>\n",
       "      <td>3.941447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>...</td>\n",
       "      <td>5.663603</td>\n",
       "      <td>-1.813225</td>\n",
       "      <td>0.216913</td>\n",
       "      <td>0.946437</td>\n",
       "      <td>6.843854</td>\n",
       "      <td>2.023906</td>\n",
       "      <td>1.602668</td>\n",
       "      <td>-2.953294</td>\n",
       "      <td>-0.892307</td>\n",
       "      <td>2.708489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.405882</td>\n",
       "      <td>0.241176</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.394118</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.339314</td>\n",
       "      <td>4.573346</td>\n",
       "      <td>-2.656280</td>\n",
       "      <td>1.711765</td>\n",
       "      <td>1.416503</td>\n",
       "      <td>2.454271</td>\n",
       "      <td>3.847449</td>\n",
       "      <td>-6.358982</td>\n",
       "      <td>0.517902</td>\n",
       "      <td>3.217355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>...</td>\n",
       "      <td>2.223941</td>\n",
       "      <td>-0.902198</td>\n",
       "      <td>2.731066</td>\n",
       "      <td>3.729349</td>\n",
       "      <td>2.098410</td>\n",
       "      <td>4.323120</td>\n",
       "      <td>-5.512739</td>\n",
       "      <td>-2.180889</td>\n",
       "      <td>1.790371</td>\n",
       "      <td>1.780517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.381910</td>\n",
       "      <td>0.206030</td>\n",
       "      <td>0.190955</td>\n",
       "      <td>0.070352</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>...</td>\n",
       "      <td>5.851831</td>\n",
       "      <td>5.742457</td>\n",
       "      <td>8.158543</td>\n",
       "      <td>1.492768</td>\n",
       "      <td>5.220162</td>\n",
       "      <td>4.387180</td>\n",
       "      <td>3.728474</td>\n",
       "      <td>2.705418</td>\n",
       "      <td>3.673166</td>\n",
       "      <td>1.467261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.155963</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>0.100917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100917</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>...</td>\n",
       "      <td>4.750781</td>\n",
       "      <td>-0.863330</td>\n",
       "      <td>3.807645</td>\n",
       "      <td>0.437162</td>\n",
       "      <td>2.909085</td>\n",
       "      <td>1.235796</td>\n",
       "      <td>1.918473</td>\n",
       "      <td>1.941098</td>\n",
       "      <td>0.911788</td>\n",
       "      <td>5.164681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732969</td>\n",
       "      <td>-0.055706</td>\n",
       "      <td>-2.960154</td>\n",
       "      <td>0.076052</td>\n",
       "      <td>5.429316</td>\n",
       "      <td>5.980188</td>\n",
       "      <td>2.518031</td>\n",
       "      <td>-1.672485</td>\n",
       "      <td>1.173908</td>\n",
       "      <td>0.871928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     readability_1  readability_3  readability_2  readability_4  noun_ratio  \\\n",
       "0         0.587719       0.131579       0.061404       0.017544    0.385965   \n",
       "1         0.563107       0.155340       0.048544       0.029126    0.417476   \n",
       "2         0.428571       0.220238       0.101190       0.065476    0.386905   \n",
       "3         0.393548       0.225806       0.077419       0.090323    0.464516   \n",
       "4         0.303571       0.348214       0.187500       0.062500    0.339286   \n",
       "..             ...            ...            ...            ...         ...   \n",
       "613       0.405882       0.241176       0.170588       0.017647    0.394118   \n",
       "614       0.474510       0.160784       0.145098       0.050980    0.419608   \n",
       "615       0.381910       0.206030       0.190955       0.070352    0.452261   \n",
       "616       0.431193       0.155963       0.183486       0.045872    0.422018   \n",
       "617       0.472868       0.155039       0.162791       0.015504    0.403101   \n",
       "\n",
       "     verb_ratio  adj_ratio  adv_ratio  prep_ratio  conj_ratio  ...        90  \\\n",
       "0      0.131579   0.061404   0.026316    0.122807    0.087719  ... -1.164104   \n",
       "1      0.165049   0.067961   0.019417    0.116505    0.009709  ...  1.280848   \n",
       "2      0.136905   0.136905   0.005952    0.130952    0.000000  ... -1.027658   \n",
       "3      0.103226   0.116129   0.006452    0.129032    0.000000  ...  2.092911   \n",
       "4      0.116071   0.232143   0.000000    0.116071    0.026786  ...  5.663603   \n",
       "..          ...        ...        ...         ...         ...  ...       ...   \n",
       "613    0.076471   0.123529   0.005882    0.135294    0.100000  ...  2.339314   \n",
       "614    0.137255   0.086275   0.003922    0.141176    0.031373  ...  2.223941   \n",
       "615    0.100503   0.105528   0.005025    0.105528    0.005025  ...  5.851831   \n",
       "616    0.146789   0.100917   0.000000    0.100917    0.009174  ...  4.750781   \n",
       "617    0.085271   0.116279   0.007752    0.124031    0.062016  ...  1.732969   \n",
       "\n",
       "           91        92        93        94        95        96        97  \\\n",
       "0    4.349712  3.254559 -0.531110  3.654962  0.230786  1.026072 -1.068444   \n",
       "1    1.549968  1.749696  0.601716  5.797670  5.229796  3.746816  0.156839   \n",
       "2   -0.169038  2.459741  0.418934  7.791171  5.558947  6.597505 -0.807560   \n",
       "3   -2.561067  2.664188 -0.502632  2.867926  5.306192  2.735043 -2.377146   \n",
       "4   -1.813225  0.216913  0.946437  6.843854  2.023906  1.602668 -2.953294   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "613  4.573346 -2.656280  1.711765  1.416503  2.454271  3.847449 -6.358982   \n",
       "614 -0.902198  2.731066  3.729349  2.098410  4.323120 -5.512739 -2.180889   \n",
       "615  5.742457  8.158543  1.492768  5.220162  4.387180  3.728474  2.705418   \n",
       "616 -0.863330  3.807645  0.437162  2.909085  1.235796  1.918473  1.941098   \n",
       "617 -0.055706 -2.960154  0.076052  5.429316  5.980188  2.518031 -1.672485   \n",
       "\n",
       "           98        99  \n",
       "0   -2.384245  4.848377  \n",
       "1   -5.438986  4.569999  \n",
       "2   -1.421728  4.696105  \n",
       "3   -2.957879  3.941447  \n",
       "4   -0.892307  2.708489  \n",
       "..        ...       ...  \n",
       "613  0.517902  3.217355  \n",
       "614  1.790371  1.780517  \n",
       "615  3.673166  1.467261  \n",
       "616  0.911788  5.164681  \n",
       "617  1.173908  0.871928  \n",
       "\n",
       "[618 rows x 114 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten Doc2Vec Embeddings column\n",
    "df = pd.concat([df.drop(['Doc2Vec Embeddings'], axis=1), df['Doc2Vec Embeddings'].apply(pd.Series)], axis=1)\n",
    "y = df['grade']\n",
    "# remove grade and Raw amd Tokenized columns from df\n",
    "X = df.drop(columns = [ 'grade','Raw', 'Tokenized', 'readability_0', 'readability_5', 'Document']) # 'grade',\n",
    "#,'readability_0', 'readability_1', 'readability_2', 'readability_3', 'readability_4', 'readability_5', 'noun_ratio', 'verb_ratio', 'adj_ratio', 'adv_ratio', 'pron_ratio', 'prep_ratio', 'conj_ratio'\n",
    "# ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
    "# replace NaN values with 0\n",
    "X = X.fillna(0)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_to_num = { 'A': 1, 'B1': 2, 'B2': 3, 'C': 4}\n",
    "num_grades = list(map(lambda x: grades_to_num[x], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make num_grades a dataframe\n",
    "num_grades = pd.DataFrame(num_grades, columns=['grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the dataset into non-augmented and augmented subsets\n",
    "mask_not_augmented = df['augmented'] == 0\n",
    "mask_augmented = df['augmented'] == 1\n",
    "\n",
    "X_non_augmented = X[mask_not_augmented]\n",
    "y_non_augmented = num_grades[mask_not_augmented]\n",
    "\n",
    "X_augmented = X[mask_augmented]\n",
    "y_augmented = num_grades[mask_augmented]\n",
    "\n",
    "# Split the non-augmented data into train and test sets\n",
    "X_train_partial, X_test, y_train_partial, y_test = train_test_split(\n",
    "    X_non_augmented, y_non_augmented,\n",
    "    test_size=0.2,  # Adjust the test size as per your requirement\n",
    "    stratify=y_non_augmented,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine the augmented data with the partial non-augmented training data\n",
    "X_train = pd.concat([X_augmented, X_train_partial])\n",
    "y_train = pd.concat([y_augmented, y_train_partial])\n",
    "\n",
    "# Now, X_train and y_train contain both augmented and non-augmented data, \n",
    "# while X_test and y_test only contain non-augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     grade\n",
       "0        1\n",
       "1        1\n",
       "2        4\n",
       "3        4\n",
       "4        4\n",
       "..     ...\n",
       "565      4\n",
       "598      3\n",
       "486      3\n",
       "556      3\n",
       "508      3\n",
       "\n",
       "[576 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the index\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X to numpy array\n",
    "X = np.array(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, num_grades, test_size = 0.20, stratify = num_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given a dataset X and grades y, return a dataset of pair-wise differences and labels (+,-) \n",
    "def to_pairs(X, y):\n",
    "    paired_X = list()\n",
    "    paired_y = list()\n",
    "    for i in range(len(X)):\n",
    "        for k in range(i+1, len(X), 1):\n",
    "                paired_X.append(np.subtract(X[i], X[k]))\n",
    "                paired_y.append(y[i] > y[k])\n",
    "    return paired_X, paired_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_diff, y_train_diff = to_pairs(X_train, y_train)\n",
    "X_test_diff, y_test_diff = to_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165600"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 60% of the data X_train_diff\n",
    "import random\n",
    "random.seed(42)\n",
    "X_train_diff_sample = random.sample(X_train_diff, int(len(X_train_diff)*0.6))\n",
    "random.seed(42)\n",
    "y_train_diff_sample = random.sample(y_train_diff, int(len(y_train_diff)*0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a few 20  as and cs and run it on 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor/anaconda3/envs/CAMeLBERT_morphosyntactic_tagger/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train_diff_sample, y_train_diff_sample)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test_diff)\n",
    "\n",
    "print(confusion_matrix(y_test_diff,y_pred))\n",
    "print(classification_report(y_test_diff,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Mapping to Grades with a Linear Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_fitted_X_train = svclassifier.predict(X_train).reshape(-1,1)\n",
    "svc_fitted_X_test = svclassifier.predict(X_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.3793103448275862\n",
      "[[ 0  0  4  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0 22  0  0  0]\n",
      " [ 0  0 16  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0  4  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(svc_fitted_X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(svc_fitted_X_test)\n",
    "\n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(svc_fitted_X_test, y_test) \n",
    "print('accuracy= {}'.format(accuracy))\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.38      1.00      0.55        22\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38        58\n",
      "   macro avg       0.06      0.17      0.09        58\n",
      "weighted avg       0.14      0.38      0.21        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor/anaconda3/envs/CAMeLBERT_morphosyntactic_tagger/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/noor/anaconda3/envs/CAMeLBERT_morphosyntactic_tagger/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/noor/anaconda3/envs/CAMeLBERT_morphosyntactic_tagger/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAMeLBERT_morphosyntactic_tagger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
