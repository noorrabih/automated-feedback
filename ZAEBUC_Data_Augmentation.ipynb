{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcbXEgykHubP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTPWMA3bIS3E"
      },
      "source": [
        "#Import Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4Hq0D7vH9VF",
        "outputId": "8ade90e1-7d6e-4da5-f46e-b0714a1ec39e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMvU71MxIIdD"
      },
      "outputs": [],
      "source": [
        "# path = path to raw essays\n",
        "raw_essays = pd.read_csv(path, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-QRrttZIYUX"
      },
      "source": [
        "# Data Augmentation with *ChatGPT*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3EeZSBsL132"
      },
      "outputs": [],
      "source": [
        "# path_to_already_augmented_IDs = path to a file that stores the IDs of essays that have already been augmented\n",
        "# path_to_augmented_essays = path to a file that contains the augmented essays\n",
        "augmented_IDS = open(path_to_already_augmented_IDs).read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-57NLJrILln"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken\n",
        "!pip install cohere\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHGzCYGIMUZQ"
      },
      "outputs": [],
      "source": [
        "downgrading_prompt='I am building a model to automatically grade Arabic essays according to CEFR. I need more data and I need you to help me with data augmentation.'+ 'I will give you an Arabic essay that was given the CEFR grade of {}.'+'I want you to modify it so it scores {}. You should simplify grammatically complex sentences'+'and replace {}-level words with {}-level ones. You can also introduce some spelling errors, at the rate expected of the target level. Here is the essay:\\' {} \\' '\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ1zDeKxaS5F"
      },
      "outputs": [],
      "source": [
        "upgrading_prompt = 'I am building a model to automatically grade Arabic essays according to CEFR. I need more data and I need you to help me with data augmentation.'+'I will give you an Arabic essay that was given the CEFR grade of {}.'+'I want you to modify it so it scores {}. You should fix some or all errors and make it more grammatically complex to suit the target level.'+'You should also replace {}-level words with {}-level ones. Here is the essay:\\' {} \\' '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KO68uK-dIkWg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': 'Bearer <api=key>',\n",
        "}\n",
        "\n",
        "\n",
        "for ID in raw_essays.index[110:120]:\n",
        "  if ID not in augmented_IDS:\n",
        "    augmented_df = pd.DataFrame(columns=['Document', 'Raw', 'to_grade', 'from_grade'])\n",
        "    ## downgrade:\n",
        "    from_grade = raw_essays.loc[ID]['grade']\n",
        "    if(from_grade in ['C1', 'B2', 'B1']):\n",
        "      for to_grade in ['A1', 'A2']:\n",
        "        json_data = {\n",
        "          'model': 'gpt-4',\n",
        "          'messages': [\n",
        "          {\n",
        "              'role': 'user',\n",
        "              'content' :  downgrading_prompt.format(from_grade, to_grade, from_grade, to_grade, raw_essays.loc[ID]['Raw']),},\n",
        "              ],\n",
        "            'temperature': 0.5,\n",
        "            }\n",
        "        response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=json_data)\n",
        "        augmented_df = augmented_df.append({'Document': ID, 'Raw': response.json()['choices'][0]['message']['content'], 'to_grade': to_grade, 'from_grade': from_grade}, ignore_index =True)\n",
        "\n",
        "    ## upgrade:\n",
        "    if(from_grade in ['A2', 'B1', 'B2']):\n",
        "      for to_grade in ['C1', 'C2']:\n",
        "        json_data = {\n",
        "          'model': 'gpt-4',\n",
        "          'messages': [\n",
        "          {\n",
        "            'role': 'user',\n",
        "            'content' :  upgrading_prompt.format(from_grade, to_grade, from_grade, to_grade, raw_essays.loc[ID]['Raw']),},\n",
        "            ],\n",
        "            'temperature': 0.5,\n",
        "            }\n",
        "        response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=json_data)\n",
        "        augmented_df = augmented_df.append({'Document': ID, 'Raw': response.json()['choices'][0]['message']['content'], 'to_grade': to_grade, 'from_grade': from_grade}, ignore_index =True)\n",
        "\n",
        "\n",
        "    #attach augmented essays to augmented_augmented.tsv file:\n",
        "    with open(path_to_augmented_essays, 'a') as f:\n",
        "      augmented_df.to_csv(f, sep='\\t', index=False, header = False)\n",
        "\n",
        "\n",
        "    ##attach ID to /content/drive/MyDrive/NLP701/Augmented_Essays/augmented_ids.txt:\n",
        "    augmented_IDS.append(ID)\n",
        "    with open(path_to_already_augmented_IDs, 'a') as f:\n",
        "      f.write(ID + '\\n')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}