{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e74c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e90945",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZAEBUC_AR_COR = pd.read_csv('ZAEBUC-v1.0/AR-all.extracted.corrected.analyzed.corrected-FINAL.tsv', encoding='utf_8',sep='\\t')\n",
    "words_df = ZAEBUC_AR_COR[ZAEBUC_AR_COR['Word'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10ce334",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZAEBUC_AR_ALL = pd.read_csv('ZAEBUC-v1.0/AR-all.alignment-FINAL.tsv', encoding='utf_8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52a7bb0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Corrected</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>وسائل</td>\n",
       "      <td>وسائل</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>التواصل</td>\n",
       "      <td>التواصل</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>الاجتماعي</td>\n",
       "      <td>الاجتماعي</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>لها</td>\n",
       "      <td>لها</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR-030-268469</td>\n",
       "      <td>اضرار</td>\n",
       "      <td>أضرار</td>\n",
       "      <td>EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33761</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>المجتمع</td>\n",
       "      <td>المجتمع</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33762</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>و</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33763</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>كيفية</td>\n",
       "      <td>وكيفية</td>\n",
       "      <td>EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33764</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>إستعمالهم</td>\n",
       "      <td>استعمالهم</td>\n",
       "      <td>EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33765</th>\n",
       "      <td>AR-130-99787</td>\n",
       "      <td>لها.</td>\n",
       "      <td>لها.</td>\n",
       "      <td>NO_CHANGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33766 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Document        Raw  Corrected  Operation\n",
       "0      AR-030-268469      وسائل      وسائل  NO_CHANGE\n",
       "1      AR-030-268469    التواصل    التواصل  NO_CHANGE\n",
       "2      AR-030-268469  الاجتماعي  الاجتماعي  NO_CHANGE\n",
       "3      AR-030-268469        لها        لها  NO_CHANGE\n",
       "4      AR-030-268469      اضرار      أضرار       EDIT\n",
       "...              ...        ...        ...        ...\n",
       "33761   AR-130-99787    المجتمع    المجتمع  NO_CHANGE\n",
       "33762   AR-130-99787          و        NaN     DELETE\n",
       "33763   AR-130-99787      كيفية     وكيفية       EDIT\n",
       "33764   AR-130-99787  إستعمالهم  استعمالهم       EDIT\n",
       "33765   AR-130-99787       لها.       لها.  NO_CHANGE\n",
       "\n",
       "[33766 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZAEBUC_AR_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c96439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO_CHANGE', 'EDIT', 'DELETE', 'INSERT'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZAEBUC_AR_ALL['Operation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dc961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_df = ZAEBUC_AR_ALL[['Document','Operation']].groupby('Document').aggregate({'Operation': (lambda x: 1- np.sum(x=='NO_CHANGE')/len(x) )}).rename(columns = {'Operation':'error_rate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26a6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR-030-268469</th>\n",
       "      <td>0.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-386369</th>\n",
       "      <td>0.237179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81027</th>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81757</th>\n",
       "      <td>0.493927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-83625</th>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99351</th>\n",
       "      <td>0.245283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99438</th>\n",
       "      <td>0.059322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99442</th>\n",
       "      <td>0.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99590</th>\n",
       "      <td>0.126214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99787</th>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               error_rate\n",
       "Document                 \n",
       "AR-030-268469    0.455621\n",
       "AR-030-386369    0.237179\n",
       "AR-030-81027     0.585366\n",
       "AR-030-81757     0.493927\n",
       "AR-030-83625     0.428571\n",
       "...                   ...\n",
       "AR-130-99351     0.245283\n",
       "AR-130-99438     0.059322\n",
       "AR-130-99442     0.311475\n",
       "AR-130-99590     0.126214\n",
       "AR-130-99787     0.291667\n",
       "\n",
       "[214 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672efc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays_df = words_df[['Document','Auto_Tokenization']].groupby(by = 'Document').agg({'Auto_Tokenization': ' '.join})\n",
    "tokenized_essays_df['Auto_Tokenization'] = tokenized_essays_df['Auto_Tokenization'].apply(lambda x : x.replace('+', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b8f410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto_Tokenization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR-030-268469</th>\n",
       "      <td>وسائل التواصل الاجتماعي ل ها أضرار و فوائد كثي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-386369</th>\n",
       "      <td>تعد وسائل التواصل الاجتماعي من أكبر المؤثرات ع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81027</th>\n",
       "      <td>قام انتشار وسائل التواصل الاجتماعي ب شكل كبير ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-81757</th>\n",
       "      <td>وسائل التواصل الاجتماعي لقد تطورت وسائل المعرف...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-030-83625</th>\n",
       "      <td>من أشهر وسائل الاتصال ب الآخرين هي الاجتماعية .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99351</th>\n",
       "      <td>ظهور الأجهزة الإلكترونية أدى إلى ظهور وسائل ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99438</th>\n",
       "      <td>وسائل التواصل الاجتماعي منذ انتشار وسائل التوا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99442</th>\n",
       "      <td>وسائل التواصل الاجتماعي إن التواصل الاجتماعي ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99590</th>\n",
       "      <td>التسامح أمر مهم جدا يجب على الفرد أخذ ه ب جدية...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR-130-99787</th>\n",
       "      <td>التواصل الاجتماعي عبارة عن مجموعة من التكنولوج...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Auto_Tokenization\n",
       "Document                                                        \n",
       "AR-030-268469  وسائل التواصل الاجتماعي ل ها أضرار و فوائد كثي...\n",
       "AR-030-386369  تعد وسائل التواصل الاجتماعي من أكبر المؤثرات ع...\n",
       "AR-030-81027   قام انتشار وسائل التواصل الاجتماعي ب شكل كبير ...\n",
       "AR-030-81757   وسائل التواصل الاجتماعي لقد تطورت وسائل المعرف...\n",
       "AR-030-83625     من أشهر وسائل الاتصال ب الآخرين هي الاجتماعية .\n",
       "...                                                          ...\n",
       "AR-130-99351   ظهور الأجهزة الإلكترونية أدى إلى ظهور وسائل ال...\n",
       "AR-130-99438   وسائل التواصل الاجتماعي منذ انتشار وسائل التوا...\n",
       "AR-130-99442   وسائل التواصل الاجتماعي إن التواصل الاجتماعي ل...\n",
       "AR-130-99590   التسامح أمر مهم جدا يجب على الفرد أخذ ه ب جدية...\n",
       "AR-130-99787   التواصل الاجتماعي عبارة عن مجموعة من التكنولوج...\n",
       "\n",
       "[214 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_essays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93df1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(doc):\n",
    "#     doc = doc.split(' ')\n",
    "#     doc = tokenizer.tokenize(doc)\n",
    "#     tokens = []\n",
    "#     for word in doc:\n",
    "#         word = word.replace('+_', ',').replace('_+',',').split(',')\n",
    "#         for tok in word:\n",
    "#             tokens.append(tok)\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66158384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.10340822 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Applying TFIDF\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1, 1), min_df=2, max_df=0.9 )\n",
    "doc2vec = vectorizer.fit_transform(tokenized_essays_df['Auto_Tokenization'])\n",
    "doc2vec = (doc2vec.toarray())\n",
    "print(\"\\n\\nScores : \\n\", doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50bcbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays_df['Auto_POS'] = words_df[['Document', 'Auto_POS']].groupby(by = 'Document', as_index = True).agg({'Auto_POS': ' '.join})\n",
    "tokenized_essays_df['Auto_POS'] = tokenized_essays_df['Auto_POS'].apply(lambda x: x.replace('+', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d643d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.03757249 0.         0.05357857 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.09170559 0.         0.04359089 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.04480017 0.         0.06388529 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Applying TFIDF\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1, 3), min_df=2, max_df=0.9)\n",
    "pos2vec = vectorizer.fit_transform(tokenized_essays_df['Auto_POS'])\n",
    "pos2vec = (pos2vec.toarray())\n",
    "print(\"\\n\\nScores : \\n\", pos2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112257b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "docs = ZAEBUC_AR_COR['Document'].apply(lambda x: x if x.startswith('<') else np.nan).dropna()\n",
    "\n",
    "grades = []\n",
    "word_count = []\n",
    "\n",
    "for xml in docs:\n",
    "    if xml != \"</doc>\":\n",
    "        doc = xmltodict.parse(xml)\n",
    "        grades.append(doc[\"doc\"][\"@CEFR\"])\n",
    "        word_count.append(doc[\"doc\"][\"@word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28729308",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((doc2vec,pos2vec, np.array(word_count).reshape(-1,1), np.array(error_rate_df['error_rate']).reshape(-1,1) ), axis = 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f48135f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 1 16  4  0  1]\n",
      " [ 0  1 15  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  0  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A2       0.00      0.00      0.00         2\n",
      "          B1       0.94      0.73      0.82        22\n",
      "          B2       0.71      0.94      0.81        16\n",
      "          C1       0.00      0.00      0.00         2\n",
      "Unassessable       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.38      0.53      0.41        43\n",
      "weighted avg       0.75      0.74      0.73        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier for X and grades\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, grades, test_size = 0.20, stratify=grades, random_state = 30)\n",
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95592790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0 20  2  0]\n",
      " [ 0  0 12  4  0]\n",
      " [ 0  0  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.54      0.91      0.68        22\n",
      "           4       0.67      0.25      0.36        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.56        43\n",
      "   macro avg       0.24      0.23      0.21        43\n",
      "weighted avg       0.52      0.56      0.48        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier for X and grades\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20, criterion='gini', random_state=22, max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f690e665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  1  0]\n",
      " [ 0  0  1  1  0]\n",
      " [ 0  0 14  8  0]\n",
      " [ 0  0 12  4  0]\n",
      " [ 0  0  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.48      0.64      0.55        22\n",
      "           4       0.29      0.25      0.27        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42        43\n",
      "   macro avg       0.15      0.18      0.16        43\n",
      "weighted avg       0.35      0.42      0.38        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# naive bayes classifier for X and grades\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,gnb_pred))\n",
    "print(classification_report(y_test,gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff5e9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 1  0 20  1  0]\n",
      " [ 0  0 11  5  0]\n",
      " [ 0  0  1  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.59      0.91      0.71        22\n",
      "           4       0.71      0.31      0.43        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60        43\n",
      "   macro avg       0.36      0.44      0.36        43\n",
      "weighted avg       0.58      0.60      0.54        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# neural network classifier for X and grades\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,mlp_pred))\n",
    "print(classification_report(y_test,mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14279ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = list(map(lambda x:'A0' if (x == 'Unassessable') else x, grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be39186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grades_to_num(grades):\n",
    "    num_grades = []\n",
    "    for x in grades:\n",
    "        match x:\n",
    "            case 'A0':\n",
    "                num_grades.append(0)\n",
    "            case 'A1':\n",
    "                num_grades.append(1)\n",
    "            case 'A2':\n",
    "                num_grades.append(2)\n",
    "            case 'B1':\n",
    "                num_grades.append(3)\n",
    "            case 'B2':\n",
    "                num_grades.append(4)\n",
    "            case 'C1':\n",
    "                num_grades.append(5)\n",
    "            case 'C2':\n",
    "                num_grades.append(6)\n",
    "    return num_grades\n",
    "num_grades = grades_to_num(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d75184cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, num_grades, test_size = 0.20, stratify = num_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90bcc633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## given a dataset X and grades y, return a dataset of pair-wise differences and labels (+,-) \n",
    "def to_pairs(X, y):\n",
    "    paired_X = list()\n",
    "    paired_y = list()\n",
    "    for i in range(len(X)):\n",
    "        for k in range(i+1, len(X), 1):\n",
    "                paired_X.append(np.subtract(X[i], X[k]))\n",
    "                paired_y.append(y[i] > y[k])\n",
    "    return paired_X, paired_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69efe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_diff, y_train_diff = to_pairs(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ae1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_diff, y_test_diff = to_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b35437e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[483  49]\n",
      " [178 193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.91      0.81       532\n",
      "        True       0.80      0.52      0.63       371\n",
      "\n",
      "    accuracy                           0.75       903\n",
      "   macro avg       0.76      0.71      0.72       903\n",
      "weighted avg       0.76      0.75      0.74       903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'C': [0.1,1, 10, 100], 'kernel' : ['linear']}\n",
    "\n",
    "# grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "# grid.fit(X_train_diff,y_train_diff)\n",
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train_diff, y_train_diff)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test_diff)\n",
    "\n",
    "print(confusion_matrix(y_test_diff,y_pred))\n",
    "print(classification_report(y_test_diff,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dfe7ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.18665215 4.04730381 4.04858788 4.04648785 4.0466915  4.05201913\n",
      " 2.91404336 2.91371026 4.04546076 2.91232702 4.04618315 4.05231736\n",
      " 2.91237224 4.0492652  2.91219017 2.91130448 2.91166974 4.05266667\n",
      " 1.78179111 0.83264642 4.04551925 2.91146243 2.90842551 5.18419844\n",
      " 0.83259025 4.04969945 2.90763601 2.91249213 5.18875025 2.90890169\n",
      " 2.91044502 2.90945366 2.91459067 2.91351035 2.90970602 2.91301125\n",
      " 5.18539528 4.05312152 4.04801162 4.04750743 2.91035789 2.91141282\n",
      " 1.7798873  5.19113363 4.05108492 5.18478311 2.91237724 2.91116106\n",
      " 4.04664531 4.04775854 4.04821061 2.91166476 4.05020035 2.91022924\n",
      " 2.90979001 2.90704884 4.04584475 4.04741216 2.91307265 4.05287043\n",
      " 4.04749495 2.91164641 2.90547357 4.05013206 2.9150042  4.04760643\n",
      " 2.9121568  2.9110789  4.0471286  4.04568905 2.91125736 4.04552821\n",
      " 2.91219958 2.91268866 4.05007154 5.18229021 2.91354098 2.90739792\n",
      " 2.9079553  0.82344613 2.90589888 2.9100898  2.91311098 4.05164965\n",
      " 4.0483985  2.90763309 2.91198123 4.04605917 2.91409127 5.18640636\n",
      " 2.91475518 4.04540744 2.91004849 4.04448306 2.91270805 2.9093094\n",
      " 2.90953382 2.90566868 2.91016246 2.90876329 2.91291038 2.91185205\n",
      " 4.0518438  4.04778716 4.05127953 2.91519227 2.90740215 2.91038452\n",
      " 4.04846889 4.04611367 2.91003143 2.91328747 4.04664224 2.91327023\n",
      " 2.91191362 4.05283185 2.90976023 2.9079399  2.91502163 4.04537995\n",
      " 2.90943029 0.82354304 4.04624142 2.90895936 2.91470047 2.90810508\n",
      " 2.90994568 2.90964365 2.91488241 2.91486267 2.90750347 4.04594902\n",
      " 4.05151821 2.9130735  5.18384711 0.8234231  4.05115942 4.04495513\n",
      " 2.90799372 1.77574497 4.04746006 4.04714345 4.05103481 1.77628948\n",
      " 2.9113265  4.05188013 2.9133547  2.91090333 2.90819988 4.04764873\n",
      " 2.91315212 2.912423   4.05170748 4.05212243 4.05168586 4.05145385\n",
      " 2.91294827 2.91004366 2.91362292 2.91120211 2.91368768 1.77304774\n",
      " 4.05428763 2.9147977  4.04625265 4.05215125 4.04802926 4.04674867\n",
      " 2.91218436 4.05287641 4.04652936]\n",
      "[5, 4, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 4, 2, 0, 4, 3, 3, 5, 0, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 5, 4, 4, 4, 3, 3, 2, 5, 4, 5, 3, 3, 4, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4, 5, 3, 3, 3, 0, 3, 3, 3, 4, 4, 3, 3, 4, 3, 5, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 0, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 5, 0, 4, 4, 3, 2, 4, 4, 4, 2, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 4, 3, 4, 4, 4, 4, 3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "svc_fitted_X_train = svclassifier.coef_ @ np.transpose(X_train)\n",
    "svc_fitted_X_train = svc_fitted_X_train.reshape(-1,1) \n",
    "svc_fitted_X_test = svclassifier.coef_ @ np.transpose(X_test)\n",
    "svc_fitted_X_test = svc_fitted_X_test.reshape(-1,1) \n",
    "\n",
    "lm= LinearRegression(fit_intercept=True).fit(svc_fitted_X_train, y_train)\n",
    "print(lm.predict(svc_fitted_X_train))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "944e17bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.56405993 3.        ]\n",
      " [3.92196842 5.        ]\n",
      " [3.95858607 4.        ]\n",
      " [4.18418967 5.        ]\n",
      " [3.71563022 4.        ]\n",
      " [4.47749463 4.        ]\n",
      " [2.30277808 3.        ]\n",
      " [3.36015901 3.        ]\n",
      " [3.13563513 3.        ]\n",
      " [3.53387512 4.        ]\n",
      " [3.82528595 4.        ]\n",
      " [2.64501417 2.        ]\n",
      " [3.69560611 4.        ]\n",
      " [2.62662155 3.        ]\n",
      " [2.57996462 2.        ]\n",
      " [4.81864589 4.        ]\n",
      " [2.96885315 4.        ]\n",
      " [3.126192   4.        ]\n",
      " [2.72698879 4.        ]\n",
      " [3.07727581 3.        ]\n",
      " [3.36371476 3.        ]\n",
      " [3.22932604 3.        ]\n",
      " [3.12771925 3.        ]\n",
      " [2.79229051 3.        ]\n",
      " [3.37710568 4.        ]\n",
      " [2.60633526 3.        ]\n",
      " [3.04484355 3.        ]\n",
      " [3.58762539 4.        ]\n",
      " [3.86327705 4.        ]\n",
      " [3.41133849 4.        ]\n",
      " [2.98200527 3.        ]\n",
      " [3.13494847 3.        ]\n",
      " [3.42902048 3.        ]\n",
      " [3.53590606 3.        ]\n",
      " [3.62238079 4.        ]\n",
      " [3.58887415 3.        ]\n",
      " [3.54300519 3.        ]\n",
      " [2.18900118 0.        ]\n",
      " [3.97448157 4.        ]\n",
      " [3.82367153 3.        ]\n",
      " [3.19809048 3.        ]\n",
      " [2.68103157 3.        ]\n",
      " [3.18190467 3.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((np.array(lm.predict(svc_fitted_X_test)).reshape(-1,1), np.array(y_test).reshape(-1,1)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68d8ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3.]\n",
      " [4. 5.]\n",
      " [4. 4.]\n",
      " [4. 5.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [2. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [3. 2.]\n",
      " [4. 4.]\n",
      " [3. 3.]\n",
      " [3. 2.]\n",
      " [5. 4.]\n",
      " [3. 4.]\n",
      " [3. 4.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 3.]\n",
      " [4. 4.]\n",
      " [4. 3.]\n",
      " [4. 3.]\n",
      " [2. 0.]\n",
      " [4. 4.]\n",
      " [4. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "predicted_grades = np.floor(np.array(lm.predict(svc_fitted_X_test)).reshape(-1,1) + 0.5)\n",
    "print(np.concatenate((predicted_grades, np.array(y_test).reshape(-1,1)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09ce8cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.61396877],\n",
       "       [0.61396877, 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.floor(np.array(lm.predict(svc_fitted_X_test)) + 0.5), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d33a961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  1 17  4  0]\n",
      " [ 0  0  5 10  1]\n",
      " [ 0  0  0  2  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, np.floor(np.array(lm.predict(svc_fitted_X_test)) + 0.5))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "307ce397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.71      0.77      0.74        22\n",
      "           4       0.62      0.62      0.62        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63        43\n",
      "   macro avg       0.27      0.28      0.27        43\n",
      "weighted avg       0.59      0.63      0.61        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,np.floor(np.array(lm.predict(svc_fitted_X_test)) + 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84cfb5b",
   "metadata": {},
   "source": [
    "## Linear Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "310589cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.627906976744186\n",
      "[[ 0  1  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  1 17  4  0]\n",
      " [ 0  0  5 10  1]\n",
      " [ 0  0  0  2  0]]\n"
     ]
    }
   ],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(svc_fitted_X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(svc_fitted_X_test)\n",
    "\n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(svc_fitted_X_test, y_test) \n",
    "print('accuracy= {}'.format(accuracy))\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7129cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.71      0.77      0.74        22\n",
      "           4       0.62      0.62      0.62        16\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63        43\n",
      "   macro avg       0.27      0.28      0.27        43\n",
      "weighted avg       0.59      0.63      0.61        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
